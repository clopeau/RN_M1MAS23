{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction \n",
        "Nous avons vu que les réseaux de neurones peuvent être utilisés dans de nombreuses applications pratiques intéressantes, allant de la classification (ou régression) de données, reconnaissance de sentiment dans un texte (on aurait pu faire de la détection de spam), reconnaissance d'images... Les applications sont nombreuses et illimitées, néanmoins maintenant que vous avez les notions suffisantes il est possible de comprendre le principe de fonctionnement d'un grand nombre d'entre elles.\n",
        "\n",
        "#Applications\n",
        "Que quelques applications...\n",
        "\n",
        "## Traduction automatiques\n",
        "\n",
        "On est ici dans un cadre dit de \"sequence to sequence\", à partir d'un vecteur de mots d'une langue A on veut construire un vecteur de mots de la langue B. Les réseaux neuroneaux récurent répondent à cette problématique, remarquez que le nombre de mots peut être différents d'un langue à l'autre. Ces réseaux prennent en compte le contexte et la sémantique de la phrase entière, plutôt que de simplement traduire chaque mot individuellement, ce qui améliore considérablement la qualité de la traduction.\n",
        "\n",
        "Sur le principe en alimentant un réseau avec des exemples de phrases et leurs traductions, on peut \"apprendre\" à convertir automatiquement. Cette traduction s'apprenant dans un sens ou dans l'autre (pas les deux à la fois).\n",
        "\n",
        "De nombreux data-set de plusieurs millions de phrases traduite sont disponibles, il est possible \"facilement\" après quelques heures de calcul d'obtenir un traducteur automatique. \n",
        "\n",
        "Google Traduction utilise une technologie de réseau de neurones  appelé NMT (Neural Machine Translation). Le NMT est basé sur l'utilisation de réseaux de neurones récurrents (RNN) pour modéliser la relation entre les séquences de mots dans deux langues différentes.\n",
        "\n",
        "Le modèle de traduction de Google est capable de traduire plus de 100 langues avec une grande précision, et il est constamment amélioré grâce à l'ajout de nouvelles données et à l'optimisation des algorithmes.\n",
        "\n",
        "Le modèle de traduction NMT utilise une architecture dite encoders et decoders pour convertir les mots d'une langue à une autre. \n",
        "\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img src=\"https://www.silicon.fr/wp-content/uploads/2016/11/Google-traduction-neural-370x196.gif\">\n",
        "</p>\n",
        "\n",
        "Cette approche fait d'une certaine manière apparaitre un encodage universel des différentes langues comme sur ce schéma extrait de Nat Commun 11, 4381 (2020) (https://rdcu.be/dapcQ) qui parle de \"deep représentation\".\n",
        "\n",
        "<p align=\"center\" width=\"70%\">\n",
        "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-020-18073-9/MediaObjects/41467_2020_18073_Fig1_HTML.png?as=webp\">\n",
        "</p>\n",
        "\n",
        "A méditer...\n",
        "\n",
        "## Les autoencodeurs\n",
        "\n",
        "Les autoencodeurs sont une architecture de réseau de neurones qui ont la particularité d'être utilisés pour la compression de données. Ils fonctionnent en apprenant à reconstruire les données d'entrée en utilisant une représentation compressée appelée code latent. L'objectif est de minimiser l'erreur de reconstruction entre les données d'entrée et la sortie décodée.\n",
        "\n",
        "<p align=\"center\" width=\"60%\">\n",
        "<img src=\"https://d3i71xaburhd42.cloudfront.net/b1786e74e233ac21f503f59d03f6af19a3699024/2-Figure1-1.png\n",
        "\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Le réseau autoencodeur est composé de deux parties principales : l'encodeur et le décodeur. L'encodeur transforme les données d'entrée en un code latent compressé, tandis que le décodeur retransforme le code latent en une sortie décodée qui doit être aussi proche que possible de l'entrée d'origine.\n",
        "\n",
        "Les autoencodeurs ont plusieurs applications, notamment dans la réduction de la dimensionnalité des données, la suppression de bruit, la génération de données synthétiques et la détection d'anomalies. Ils sont également utilisés dans des domaines tels que la reconnaissance de la parole, la reconnaissance d'images et la détection d'objets.\n",
        "\n",
        "## Les encodeurs\n",
        "\n",
        "La difficultée permanente des réseaux de neurone et l'apprentissage, ce grand temps de calcul avec l'amélioration que l'on peut apporter en utilisant une fois de plus un grand temps de calcul... Néanmoins une fois les poinds du réseau trouvé il n'est plus besoin de le recalculé.\n",
        "\n",
        "Si on chématise un réseau de classifiction d'image par un réseau de convolution :\n",
        "\n",
        "<p align=\"center\" width=\"60%\">\n",
        "<img src=\"https://kongakura.fr/images/dessin5-5d6f33eee6b05.png\n",
        "\">\n",
        "</p>\n",
        "\n",
        "On voit apparaitre une phase \"encodage\" qui pourrait être entrainée à l'aide d'un autoencoder vu précédemment. Autrement dit il est possible de spécialiser certaines parties du réseau et d'utiliser des coefficients déjà calculés.\n",
        "\n",
        "Un grand concours de reconnaissance d'images (Large Scale Visual Recognition Challenge) a été organisé chaque année de 2010 à 2017 par l'Université de Stanford et avait pour objectif d'évaluer les performances des algorithmes de reconnaissance d'objets dans des images.\n",
        "\n",
        "Le défi utilise une base de données massive d'images appelée **ImageNet**, qui contient plus de 14 millions d'images étiquetées avec plus de 20 000 catégories d'objets. Les participants au défi devaient développer des algorithmes capables d'identifier correctement les objets dans un ensemble de données de test de 100 000 images.\n",
        "\n",
        "Ce concours a permis l'entrainement de nombreux réseaux qui sont actuellement librement disponible et sont connus sous leurs acronymes dans différentes versions :\n",
        "**AlexNet**, **VGGNet** (VGG16, VGG19), **GoogLeNet** (InceptionV1, InceptionV2, InceptionV3, InceptionV4), **ResNet** (ResNet50, ResNet101, ResNet152), **DenseNet** (DenseNet121, DenseNet169, DenseNet201)...\n",
        "\n",
        "Sous Keras on peut charger l'architecture et les poids de ses réseaux en utilisant une commande de type"
      ],
      "metadata": {
        "id": "qe9Q8-cvC016"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# Charger le modèle pré-entraîné VGG16\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Geler les poids de la partie de l'encodeur pré-entraînée\n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuwxpUYSplCH",
        "outputId": "3371389d-dcd8-45d6-99d0-24002c64afcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il devient possible donc de geler ou de ré-entrainer tout ou partie du réseau"
      ],
      "metadata": {
        "id": "zRYk1-QWqdfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5643glkGZV_",
        "outputId": "a060ab53-af82-4347-d828-31786a993bf5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici on a la partie \"encoder\" il devient possible de compléter avec un réseau dense de classification, ou reconstruction d'images, reconnaissance d'objets. Cette fois la seconde partie comporte des poids entrainable à l'aide de données d'apprentissage. L'idée est de penser que l'encodeur caractérise l'image dans un espace latent suffisemment riche pour pouvoir discriminer l'image et donc la reconstruire ou classifier..."
      ],
      "metadata": {
        "id": "kwl6J5Gdq9zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coloration d'images\n",
        "\n",
        "Aussi étrange que cela paraissent il est possible de colorier automatiquement des images noir et blanc. Cela peut sembler étrange que d'une information dégradée on puisse retrouvé l'éclat des couleurs !\n",
        "\n",
        "La colorisation c'est fait de nombreuses années à la main en coloriant directement la pélicule... \n",
        "\n",
        "Les réseaux de neurones peuvent être entraînés à reconnaître les caractéristiques des images en niveaux de gris ou en noir et blanc, telles que les contours, les textures et les formes, et à ajouter des couleurs appropriées en fonction de ces caractéristiques. Les réseaux de neurones peuvent apprendre à partir de nombreux exemples d'images colorées pour prédire les couleurs qui seraient utilisées dans des images similaires.\n",
        "\n",
        "Les réseaux de neurones peuvent être utilisés de plusieurs façons pour la coloration d'images. Par exemple, certaines méthodes de coloration d'images utilisent des réseaux de neurones pour prédire les couleurs qui seraient utilisées dans une image en noir et blanc en utilisant des informations contextuelles sur l'image et en considérant les couleurs qui ont été utilisées dans des images similaires. Ces méthodes peuvent également utiliser des techniques de régularisation pour éviter la sur-coloration et pour améliorer la qualité de l'image colorée.\n",
        "\n",
        "Je vous invite à regarder le notebook [Color.ipynb](https://github.com/clopeau/RN_M1MAS23/blob/main/Color_.ipynb) comme illustration.\n"
      ],
      "metadata": {
        "id": "m5lpoRI9rmUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "Nous avons vu comment ces modèles mathématiques peuvent être utilisés pour la reconnaissance d'images, la classification mais aussi la segmentation et bien d'autres applications. Nous avons examiné les différents types de réseaux de neurones, y compris les réseaux de neurones classiques (RN), les réseaux de neurones récurrents (RNN) et les réseaux de neurones convolutionnels (CNN).\n",
        "\n",
        "Nous avons également entrevu comment les réseaux de neurones ont révolutionné de nombreux domaines, tels que la reconnaissance d'images et la traduction automatique... Ces modèles ont également conduit à des avancées importantes dans l'intelligence artificielle et le machine learning, et ont ouvert de nouvelles perspectives pour les applications de l'apprentissage automatique.\n",
        "\n",
        "En ce qui concerne l'avenir des réseaux de neurones, nous pouvons nous attendre à des développements passionnants dans les années à venir. Les réseaux de neurones vont continuer à se développer et à se perfectionner, permettant ainsi des avancées significatives dans les domaines tels que la médecine, la finance, l'énergie, l'agriculture et bien d'autres encore. Nous pouvons également nous attendre à une amélioration continue des techniques de formation, ainsi qu'à de nouveaux développements en matière d'interprétabilité et de compréhension de la façon dont les réseaux de neurones prennent des décisions.\n",
        "\n",
        "En fin de compte, nous pouvons être sûrs que les réseaux de neurones continueront à jouer un rôle important dans l'avenir de l'intelligence artificielle et du machine learning. Avec leurs capacités de traitement de l'information avancées et leur grande flexibilité, les réseaux de neurones représentent une technologie très prometteuse pour de nombreuses applications à venir."
      ],
      "metadata": {
        "id": "Mj4GbRQnv1nl"
      }
    }
  ]
}