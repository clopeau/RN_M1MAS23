{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyi8vkyXxRyA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Réseaux de neurones convolutifs\n",
        "## Introduction\n",
        "Les réseaux de neurones convolutifs, également appelés CNN (Convolutional Neural Networks) en anglais, sont une classe de réseaux de neurones artificiels qui ont été inspirés par la façon dont le cerveau traite les informations visuelles. Ces réseaux sont particulièrement efficaces pour la reconnaissance d'images, mais peuvent également être utilisés pour la reconnaissance de la parole, la classification de texte et d'autres tâches similaires.\n",
        "\n",
        "Les premiers travaux dans ce domaine remontent aux années 1980, lorsque les chercheurs ont commencé à explorer les réseaux de neurones pour la reconnaissance de caractères manuscrits. Cependant, ces réseaux étaient relativement simples et peu profonds, et leur précision était limitée.\n",
        "\n",
        "Au début des années 1990, **Yann LeCun** et ses collègues ont développé le **LeNet-5**, qui était un réseau de neurones convolutif plus complexe et profond. LeLeNet-5 a été utilisé pour la reconnaissance de chiffres manuscrits et a connu un grand succès, ouvrant la voie à des réseaux plus avancés pour la reconnaissance d'images.\n",
        "\n",
        "Au cours des années suivantes, des chercheurs ont continué à améliorer les réseaux de neurones convolutifs, en explorant des techniques telles que l'utilisation de filtres plus larges, de couches de regroupement (*MaxPooling*, *AveragePooling*), et de couches de régularisation (*Dropout*). Ces techniques ont permis aux réseaux de neurones convolutifs de devenir plus profonds et plus précis.\n",
        "\n",
        "Cependant, ce n'est que dans les années 2010 que les réseaux de neurones convolutifs ont vraiment pris leur envol, grâce à l'augmentation de la puissance de calcul et à l'abondance de données d'entraînement. En 2012, le réseau de neurones convolutif **AlexNet** a remporté le concours **ImageNet** (https://www.image-net.org/), qui était considéré comme le principal défi en reconnaissance d'images à l'époque. Depuis lors, les réseaux de neurones convolutifs ont été utilisés pour une variété de tâches, allant de la reconnaissance faciale à la conduite autonome.\n",
        "\n",
        "Aujourd'hui, les réseaux de neurones convolutifs sont largement utilisés dans les domaines de la vision par ordinateur, de la reconnaissance de la parole, de la traduction automatique, et bien plus encore."
      ],
      "metadata": {
        "id": "PcRERI1_yN7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La convolution\n",
        "\n",
        "la convolution (discrète) est un moyen de faire passer un filtre (également appelé noyau ou kernel) sur le signal d'entrée en effectuant une multiplication point par point entre le filtre et une partie du signal d'entrée, puis en sommant les résultats (principe de la convolution de fonctions en mathématiques). Cette opération est effectuée à différentes positions du signal d'entrée pour produire une sortie convoluée.\n",
        "\n",
        "\n",
        "### En dimension 1\n",
        "\n",
        "Si on regarde un filtre de taille 3 avec les poids w1, w2 et w3 :\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img src=https://files.ai-pool.com/d/5UQz1zI.jpg>\n",
        "</p>\n",
        "\n",
        "On multiplie successivement chaque séquence d'ici 3 éléments d'entrée avec le filtre dont on fait la somme pour mettre sur le signal de sortie.\n",
        "\n",
        "A remarquer ici l'ajout de 0 aux extrémités pour conserver la taille du signal. Sinon le signal aurait été de taille 6 en sortie suivant la formule **outputSize=(InputSize-KernelSize)+1**. D'une façon générale les fonctions de convolutions donne la possibilité de conserver ou pas la taille du signal.\n",
        "\n",
        "Cette convolution peut correspondre à des opérations connues \n",
        "* [w1,w2]=[1/2,1/2] moyenne mobile sur 2 valeur\n",
        "* [w1,w2]=[-1,1] dérivée (discrète) du signal (différences finies)\n",
        "* [w1,w2,w3]=[1,-2,1]  dérivée seconde (discrète) du signal (différences finies)\n",
        "* [w1,w2,w3]=[1/4,1/2,1/4] Filtre gaussien ou moyenne gaussienne\n",
        "* etc... "
      ],
      "metadata": {
        "id": "r1hIGFbP16Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "\n",
        "# Créer un vecteur d'entrée aléatoire avec 10 valeurs\n",
        "x = np.random.random((10, 1))\n",
        "\n",
        "# Créer un modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajouter une couche de convolution 1D avec 8 filtres et une fenêtre de taille 3\n",
        "model.add(Conv1D(filters=1, kernel_size=3, input_shape=(None, 1)))\n",
        "\n",
        "# Faire une prédiction avec le modèle\n",
        "y = model.predict(x.reshape(1, 10, 1))\n",
        "\n",
        "# Afficher la forme de la sortie\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgxCIufx9rBI",
        "outputId": "76a98f76-8820-460e-96e9-e082a2eb0f17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "[[0.21375505]\n",
            " [0.57626906]\n",
            " [0.76388313]\n",
            " [0.13166188]\n",
            " [0.27592543]\n",
            " [0.81902654]\n",
            " [0.04983511]\n",
            " [0.62186388]\n",
            " [0.70867088]\n",
            " [0.90780831]]\n",
            "[[[-0.1788719 ]\n",
            "  [-0.0051293 ]\n",
            "  [-0.7386911 ]\n",
            "  [-0.3663745 ]\n",
            "  [ 0.3522581 ]\n",
            "  [-1.0450151 ]\n",
            "  [ 0.03398091]\n",
            "  [-0.5240112 ]]]\n",
            "(1, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### En dimension 2\n",
        "\n",
        "Le principe se généralise en dimension supérieur, la filtre devient une matrice de taille nxp (3x3 sur l'illustration ci dessouse)\n",
        "\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1066/format:webp/1*un5WgQMwfLw9Pi_I4qWFqg.png\">\n",
        "</p>\n",
        "\n",
        "De même qu'en 1d on peut retrouver des filtres connus en 2d\n",
        "* $\\left[\\begin{array}{ccc}\n",
        "1/4 & 1/4\\\\\n",
        "1/4 & 1/4\n",
        "\\end{array}\\right]$ Patch de moyenne sur 4 pixel\n",
        "* $\\left[\\begin{array}{ccc}\n",
        "-1 & 1\\\\\n",
        "-1 & 1\n",
        "\\end{array}\\right]$ dérivée en x\n",
        "* $\\left[\\begin{array}{ccc}\n",
        "0 & 1 & 0\\\\\n",
        "1 & -4 & 1\\\\\n",
        "0 & 1 &0\n",
        "\\end{array}\\right]$ Opérateur du laplacien\n",
        "* $\\left[\\begin{array}{ccc}\n",
        "0 & 1/8 & 0\\\\\n",
        "1/8 & 1/2 & 1/8\\\\\n",
        "0 & 1/8 &0\n",
        "\\end{array}\\right]$ Filtre gaussien\n",
        "* etc ..."
      ],
      "metadata": {
        "id": "2ZE3crJ07UJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "\n",
        "# Créer une image d'entrée aléatoire avec 10 lignes, 10 colonnes et 1 canal\n",
        "x = np.random.random((4, 4, 1))\n",
        "\n",
        "# Créer un modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajouter une couche de convolution 2D avec 8 filtres, une fenêtre de taille 3x3 et une fonction d'activation ReLU\n",
        "model.add(Conv2D(filters=1, kernel_size=(3, 3), activation='relu', input_shape=(None, None, 1)))\n",
        "\n",
        "# Faire une prédiction avec le modèle\n",
        "y = model.predict(x.reshape(1, 4, 4, 1))\n",
        "\n",
        "# Afficher la forme de la sortie\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQKpZlI-nMF",
        "outputId": "4ee090e3-1403-49b9-98ce-bfdd7c9dc8a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n",
            "[[[0.25883724]\n",
            "  [0.71365534]\n",
            "  [0.2063048 ]\n",
            "  [0.5990372 ]]\n",
            "\n",
            " [[0.28229898]\n",
            "  [0.77139276]\n",
            "  [0.6513154 ]\n",
            "  [0.26381664]]\n",
            "\n",
            " [[0.62325322]\n",
            "  [0.31754893]\n",
            "  [0.32703107]\n",
            "  [0.91779997]]\n",
            "\n",
            " [[0.16236988]\n",
            "  [0.50904034]\n",
            "  [0.48776992]\n",
            "  [0.05051329]]]\n",
            "[[[[0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]]]]\n",
            "(1, 2, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sous-échantillonnage par valeur maximale (max pooling) \n",
        "\n",
        "Cette opération à pour but de réduire la taille du signal d'entrée tout en conservant certaine caractéristiques de l'image (ou signal 1d)\n",
        "\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img width=\"50%\" src=\"https://production-media.paperswithcode.com/methods/MaxpoolSample2.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "_SLShfXE_YOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Régularisation (Dropout)\n",
        "\n",
        "Le dropout est une technique de régularisation (ou troncature) qui est utilisée pour réduire le surapprentissage dans les réseaux de neurones. L'idée derrière le dropout est de désactiver aléatoirement un certain nombre de neurones dans une couche donnée pendant l'entraînement. Cela force le réseau à apprendre des caractéristiques plus robustes et généralisables, plutôt que de simplement mémoriser le jeu de données d'entraînement."
      ],
      "metadata": {
        "id": "E04buAAcA1zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Créer un modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajouter une couche dense\n",
        "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
        "\n",
        "# Ajouter une couche de dropout\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Ajouter une autre couche dense\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "heJn8VNKA-nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning\n",
        "\n",
        "L'utilisation de la convolution ainsi que du pooling, dropout permet de fabriquer des réseaux avec une capacité d'apprentissage extêment poussé. \n",
        "\n",
        "Voici un des premier réseau mis au point par **Yann LeCun** et son équipe pour faire un des premier réseau extrêment compétitif pour la reconnaissance de caractère manuscrits. Noté la taille ici de 32x32 pixel de l'image d'entrée (nous sommes en 1990).\n",
        "\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img width=\"90%\" src=\"https://www.researchgate.net/profile/Pascal-Scalart/publication/317267407/figure/fig13/AS:667887685627913@1536248241501/Figure-Reseau-convolutionnel-LeNet-5-Le-nombre-de-couches-celui-des-cartes-ainsi-que.ppm\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "oEoM0PpMB42a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWLqVs2HCh6E",
        "outputId": "1792f3eb-74b2-4922-dff2-4d5d47842dcb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 30, 30, 6)         60        \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 15, 15, 6)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 13, 13, 16)        880       \n",
            "                                                                 \n",
            " average_pooling2d_2 (Averag  (None, 6, 6, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               69240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,194\n",
            "Trainable params: 81,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le principe est dans un premier temps d'encoder les images ou plus particulièrement d'en extraire les caractéristiques. En second lieu on finit par un réseau dense classique de classification.\n",
        "\n",
        "<p align=\"center\" width=\"100%\">\n",
        "<img width=\"90%\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5b/Typical_cnn_fr.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "bfmsF-zhFPnn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GyTQScvFwO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}